{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom transformers import RobertaModel, RobertaTokenizer\nfrom sklearn.metrics import roc_auc_score, f1_score, hamming_loss\nfrom transformers import EvalPrediction\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T07:06:10.175769Z","iopub.execute_input":"2024-04-14T07:06:10.176087Z","iopub.status.idle":"2024-04-14T07:06:31.631566Z","shell.execute_reply.started":"2024-04-14T07:06:10.176059Z","shell.execute_reply":"2024-04-14T07:06:31.630778Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n  device = torch.device('cuda')\nelse:\n  device = torch.device('cpu')\n\nlabels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'Z']","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:06:32.825002Z","iopub.execute_input":"2024-04-14T07:06:32.826036Z","iopub.status.idle":"2024-04-14T07:06:32.857749Z","shell.execute_reply.started":"2024-04-14T07:06:32.825996Z","shell.execute_reply":"2024-04-14T07:06:32.856533Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class RoBERTaClass(torch.nn.Module):\n    def __init__(self):\n        super(RoBERTaClass, self).__init__()\n        self.roberta_model = RobertaModel.from_pretrained(\"roberta-base\",return_dict = True)\n        self.pre_classifier = torch.nn.Linear(768,768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.activation = torch.nn.Tanh()\n        self.classifier = torch.nn.Linear(768, 14)\n\n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.roberta_model(\n            input_ids,\n            attention_mask=attn_mask,\n            token_type_ids=token_type_ids\n        )\n        output_pre_classifier = self.pre_classifier(output.pooler_output)\n        output_dropout = self.dropout(output_pre_classifier)\n        output_activation = self.activation(output_dropout)\n        output = self.classifier(output_activation)\n        return output\n\nmodel = RoBERTaClass()\nmodel.to(device)\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base',truncation=True, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:06:33.145657Z","iopub.execute_input":"2024-04-14T07:06:33.146344Z","iopub.status.idle":"2024-04-14T07:06:37.959002Z","shell.execute_reply.started":"2024-04-14T07:06:33.146316Z","shell.execute_reply":"2024-04-14T07:06:37.958191Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b285eeca1a8f43e4b855b44038d93137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4dc6f141c5747468e455e2442586f5c"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d06933ab605c4af4991367388ad17823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ecfa8a1fdd4416bad0967fa11ad206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a137a8b4d8534176958573801d2fe898"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3eca4df8dca41948fcfe7a4f1954887"}},"metadata":{}}]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.text = df['Text']\n        self.targets = self.df[labels].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        title = str(self.text[index])\n        title = \" \".join(title.split())\n\n        inputs = self.tokenizer.encode_plus(\n            title,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index])\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:06:37.960713Z","iopub.execute_input":"2024-04-14T07:06:37.961018Z","iopub.status.idle":"2024-04-14T07:06:37.969282Z","shell.execute_reply.started":"2024-04-14T07:06:37.960994Z","shell.execute_reply":"2024-04-14T07:06:37.968341Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def output_labels(outputs, threshold=0.5):\n  sigmoid = torch.nn.Sigmoid()\n  probs = sigmoid(outputs)\n  preds = np.zeros(probs.shape)\n  preds[np.where(probs.cpu()>=threshold)] = 1\n  return preds\n\ndef calculate_accuracy(preds, targets):\n\n    labels = targets.cpu().numpy()\n    row_comparison = np.equal(preds, labels)\n    num_same_positions = np.sum(row_comparison, axis=1)\n    n_correct = np.sum(num_same_positions == preds.shape[1])\n\n    return n_correct\n\ndef metrics(predictions, labels):\n    y_true = labels\n    y_pred = predictions\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n    # Calculate micro average\n    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n\n    # Calculate macro average\n    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n\n    # Print precision, recall, and F1-score for each class\n    for i in range(len(precision)):\n        print(f\"Class {i}:\")\n        print(f\"  Precision: {precision[i]}\")\n        print(f\"  Recall: {recall[i]}\")\n        print(f\"  F1-Score: {f1[i]}\")\n        print()\n\n    # Print aggregate metrics\n    print(\"Aggregate Metrics:\")\n    print(f\"  Micro Average:\")\n    print(f\"    Precision: {micro_precision}\")\n    print(f\"    Recall: {micro_recall}\")\n    print(f\"    F1-Score: {micro_f1}\")\n    print()\n    print(f\"  Macro Average:\")\n    print(f\"    Precision: {macro_precision}\")\n    print(f\"    Recall: {macro_recall}\")\n    print(f\"    F1-Score: {macro_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:06:37.970741Z","iopub.execute_input":"2024-04-14T07:06:37.971110Z","iopub.status.idle":"2024-04-14T07:06:37.984729Z","shell.execute_reply.started":"2024-04-14T07:06:37.971074Z","shell.execute_reply":"2024-04-14T07:06:37.983915Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def test_inference(test_data_loader,model):\n    total_targets = []\n    total_outputs = []\n    model.eval()\n    for batch_idx, data in tqdm(enumerate(test_data_loader)):\n        with torch.no_grad():\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n\n            outputs = model(ids, mask, token_type_ids)\n            total_targets.extend(targets.tolist())\n            preds = output_labels(outputs,0.5)\n            total_outputs.extend(preds)\n    metrics(total_outputs,total_targets)\n          ","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:10:23.579473Z","iopub.execute_input":"2024-04-14T07:10:23.579801Z","iopub.status.idle":"2024-04-14T07:10:23.587091Z","shell.execute_reply.started":"2024-04-14T07:10:23.579776Z","shell.execute_reply":"2024-04-14T07:10:23.586111Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\ndf_test = pd.read_csv('/kaggle/input/test-data/test1.csv')\ntest_dataset = Dataset(df_test, tokenizer, 256)\ntest_data_loader = torch.utils.data.DataLoader(test_dataset,\n    batch_size=32,\n    shuffle=True,\n    num_workers=0\n)\nmodel.load_state_dict(torch.load('/kaggle/input/val-model/best_val_roberta_model (1).pth'))\ntest_inference(test_data_loader,model)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:10:24.413207Z","iopub.execute_input":"2024-04-14T07:10:24.414077Z","iopub.status.idle":"2024-04-14T07:11:18.706792Z","shell.execute_reply.started":"2024-04-14T07:10:24.414043Z","shell.execute_reply":"2024-04-14T07:11:18.705848Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"157it [00:53,  2.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Class 0:\n  Precision: 0.788637266587207\n  Recall: 0.8508358336905272\n  F1-Score: 0.8185567010309278\n\nClass 1:\n  Precision: 0.9706131078224102\n  Recall: 0.9826626712328768\n  F1-Score: 0.9766007232503723\n\nClass 2:\n  Precision: 0.8913286192780052\n  Recall: 0.9000375798571966\n  F1-Score: 0.8956619296933434\n\nClass 3:\n  Precision: 0.9316965690903368\n  Recall: 0.9340485957715368\n  F1-Score: 0.9328710999054524\n\nClass 4:\n  Precision: 0.8316628701594533\n  Recall: 0.933282208588957\n  F1-Score: 0.8795470970850398\n\nClass 5:\n  Precision: 0.8070776255707762\n  Recall: 0.7881828316610925\n  F1-Score: 0.7975183305132544\n\nClass 6:\n  Precision: 0.8124833288877034\n  Recall: 0.9114302812687014\n  F1-Score: 0.8591171908052461\n\nClass 7:\n  Precision: 0.4962686567164179\n  Recall: 0.24181818181818182\n  F1-Score: 0.32518337408312953\n\nClass 8:\n  Precision: 0.7721179624664879\n  Recall: 0.5207956600361664\n  F1-Score: 0.6220302375809935\n\nClass 9:\n  Precision: 0.6486988847583643\n  Recall: 0.6221033868092691\n  F1-Score: 0.6351228389444951\n\nClass 10:\n  Precision: 0.6899841017488076\n  Recall: 0.5643693107932379\n  F1-Score: 0.6208869814020028\n\nClass 11:\n  Precision: 0.8745115067303517\n  Recall: 0.9345707656612529\n  F1-Score: 0.9035441902198296\n\nClass 12:\n  Precision: 0.8126380910296067\n  Recall: 0.7943844492440605\n  F1-Score: 0.8034076015727392\n\nClass 13:\n  Precision: 0.7779369627507163\n  Recall: 0.6979434447300771\n  F1-Score: 0.7357723577235773\n\nAggregate Metrics:\n  Micro Average:\n    Precision: 0.8539968490992533\n    Recall: 0.8698154672620085\n    F1-Score: 0.8618335781560529\n\n  Macro Average:\n    Precision: 0.7932611109711889\n    Recall: 0.7626046572259381\n    F1-Score: 0.7718443324150289\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-04-14T07:03:20.397826Z","iopub.execute_input":"2024-04-14T07:03:20.398383Z","iopub.status.idle":"2024-04-14T07:03:20.423338Z","shell.execute_reply.started":"2024-04-14T07:03:20.398355Z","shell.execute_reply":"2024-04-14T07:03:20.422241Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      A  B  C  D  E  F  G  H  I  J  L  M  N  Z  \\\n0     1  1  1  0  0  0  0  0  0  0  0  0  0  0   \n1     1  1  0  1  1  0  1  0  0  0  0  0  0  0   \n2     0  1  0  0  1  1  1  1  1  0  0  0  1  0   \n3     0  1  1  0  1  1  1  1  0  0  1  1  1  0   \n4     1  1  0  1  1  0  1  0  0  0  1  0  0  0   \n...  .. .. .. .. .. .. .. .. .. .. .. .. .. ..   \n4995  1  1  1  1  1  0  1  0  0  0  0  1  0  0   \n4996  0  1  1  1  1  0  1  0  0  0  0  0  0  0   \n4997  0  1  1  0  1  1  0  0  1  1  0  1  1  0   \n4998  1  1  0  1  0  0  1  0  0  0  0  0  0  0   \n4999  0  1  1  1  1  0  1  0  0  0  0  0  0  1   \n\n                                                   Text  \n0     Infertility in a Maltese poodle as a result of...  \n1     Conebulization of surfactant and urokinase res...  \n2     A pilot study of the mental workload of object...  \n3     Validation of a psychophysiological waking ere...  \n4     Met-Gly-Cys motif from G-protein alpha subunit...  \n...                                                 ...  \n4995  The effects on synovial permeability and synov...  \n4996  [Characteristics of the mitotic cycle of cells...  \n4997  Initial learning curve for robot-assisted part...  \n4998  Action of fatty acids on the exocrine pancreat...  \n4999  [Detection of metallo-beta-lactamase in Pseudo...  \n\n[5000 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>J</th>\n      <th>L</th>\n      <th>M</th>\n      <th>N</th>\n      <th>Z</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Infertility in a Maltese poodle as a result of...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Conebulization of surfactant and urokinase res...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A pilot study of the mental workload of object...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Validation of a psychophysiological waking ere...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Met-Gly-Cys motif from G-protein alpha subunit...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The effects on synovial permeability and synov...</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[Characteristics of the mitotic cycle of cells...</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Initial learning curve for robot-assisted part...</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Action of fatty acids on the exocrine pancreat...</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[Detection of metallo-beta-lactamase in Pseudo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}