{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom transformers import RobertaModel, RobertaTokenizer\nfrom sklearn.metrics import roc_auc_score, f1_score, hamming_loss\nfrom transformers import EvalPrediction\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RoBERTaClass(torch.nn.Module):\n    def __init__(self):\n        super(RoBERTaClass, self).__init__()\n        self.roberta_model = RobertaModel.from_pretrained(\"roberta-base\",return_dict = True)\n        self.pre_classifier = torch.nn.Linear(768,768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.activation = torch.nn.Tanh()\n        self.classifier = torch.nn.Linear(768, 14)\n\n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.roberta_model(\n            input_ids,\n            attention_mask=attn_mask,\n            token_type_ids=token_type_ids\n        )\n        output_pre_classifier = self.pre_classifier(output.pooler_output)\n        output_dropout = self.dropout(output_pre_classifier)\n        output_activation = self.activation(output_dropout)\n        output = self.classifier(output_activation)\n        return output\n\nmodel = RoBERTaClass()\nmodel.to(device)\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base',truncation=True, do_lower_case=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.text = df['Text']\n        self.targets = self.df[labels].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        title = str(self.text[index])\n        title = \" \".join(title.split())\n\n        inputs = self.tokenizer.encode_plus(\n            title,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index])\n        }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output_labels(outputs, threshold=0.5):\n  sigmoid = torch.nn.Sigmoid()\n  probs = sigmoid(outputs)\n  preds = np.zeros(probs.shape)\n  preds[np.where(probs.cpu()>=threshold)] = 1\n  return preds\n\ndef calculate_accuracy(preds, targets):\n\n    labels = targets.cpu().numpy()\n    row_comparison = np.equal(preds, labels)\n    num_same_positions = np.sum(row_comparison, axis=1)\n    n_correct = np.sum(num_same_positions == preds.shape[1])\n\n    return n_correct\n\ndef metrics(predictions, labels):\n    y_true = labels\n    y_pred = predictions\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n    # Calculate micro average\n    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n\n    # Calculate macro average\n    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n\n    # Print precision, recall, and F1-score for each class\n    for i in range(len(precision)):\n        print(f\"Class {i}:\")\n        print(f\"  Precision: {precision[i]}\")\n        print(f\"  Recall: {recall[i]}\")\n        print(f\"  F1-Score: {f1[i]}\")\n        print()\n\n    # Print aggregate metrics\n    print(\"Aggregate Metrics:\")\n    print(f\"  Micro Average:\")\n    print(f\"    Precision: {micro_precision}\")\n    print(f\"    Recall: {micro_recall}\")\n    print(f\"    F1-Score: {micro_f1}\")\n    print()\n    print(f\"  Macro Average:\")\n    print(f\"    Precision: {macro_precision}\")\n    print(f\"    Recall: {macro_recall}\")\n    print(f\"    F1-Score: {macro_f1}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_inference(test_data_loader,model):\n    total_targets = []\n    total_outputs = []\n    model.eval()\n    for batch_idx, data in (enumerate(test_data_loader)):\n        with torch.no_grad():\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n\n            outputs = model(ids, mask, token_type_ids)\n            total_targets.extend(targets.tolist())\n            preds = output_labels(outputs,0.5)\n            total_outputs.extend(preds)\n          ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('sample_dataframe.csv')\ntest_dataset = Dataset(df_test, tokenizer, 256)\ntest_data_loader = torch.utils.data.DataLoader(test_dataset,\n    batch_size=32,\n    shuffle=True,\n    num_workers=0\n)","metadata":{},"execution_count":null,"outputs":[]}]}